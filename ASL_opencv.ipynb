{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982c181",
   "metadata": {},
   "source": [
    "# Импортируем библеотеки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a668d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dense, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735253e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729d9c2",
   "metadata": {},
   "source": [
    "Добавляем слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85330d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83bbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d184ee",
   "metadata": {},
   "source": [
    "# Запуск камеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb50a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8bf32",
   "metadata": {},
   "source": [
    "Функции обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_from_landmarks(landmarks, img_size):\n",
    "    img = np.zeros((img_size[0], img_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Определите область, где располагается рука\n",
    "    hand_area = get_hand_area(landmarks, img_size)\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        x = int(landmark.x * img_size[0])\n",
    "        y = int(landmark.y * img_size[1])\n",
    "\n",
    "        # Отрисовать точку на изображении только внутри области руки\n",
    "        if is_point_inside_hand_area(x, y, 0, hand_area):  # z-координата в данном случае не используется\n",
    "            img = cv2.circle(img, (x, y), 3, (255, 255, 255), -1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_hand_area(landmarks, img_size):\n",
    "    # Простой прямоугольник, охватывающий включенные точки\n",
    "    active_points_x = [i for i, value in enumerate(landmarks) if value.x == 1]\n",
    "    active_points_y = [i for i, value in enumerate(landmarks) if value.y == 1]\n",
    "    active_points_z = [i for i, value in enumerate(landmarks) if value.z == 1]\n",
    "\n",
    "    min_x = min(active_points_x) if active_points_x else 0\n",
    "    min_y = min(active_points_y) if active_points_y else 0\n",
    "    min_z = min(active_points_z) if active_points_z else 0\n",
    "    max_x = max(active_points_x) if active_points_x else img_size[0]\n",
    "    max_y = max(active_points_y) if active_points_y else img_size[1]\n",
    "    max_z = max(active_points_z) if active_points_z else 1  # Предполагается, что z в диапазоне от 0 до 1\n",
    "\n",
    "    return (min_x, min_y, min_z, max_x, max_y, max_z)\n",
    "\n",
    "def is_point_inside_hand_area(x, y, z, hand_area):\n",
    "    min_x, min_y, min_z, max_x, max_y, max_z = hand_area\n",
    "    return min_x <= x <= max_x and min_y <= y <= max_y and min_z <= z <= max_z\n",
    "\n",
    "def draw_hand_landmarks(frame, landmarks, img_size):\n",
    "    for landmark in landmarks:\n",
    "        x = int(landmark.x * img_size[0])\n",
    "        y = int(landmark.y * img_size[1])\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)  # Отрисовка кружка вокруг точки\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386f951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Обработка кадра Mediapipe\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks = results.multi_hand_landmarks[0].landmark\n",
    "        print(landmarks)\n",
    "        # Преобразование landmarks в изображение\n",
    "        img_size = (32, 32)  # Настройте размер изображения под требования вашей нейронной сети\n",
    "        img_array = create_image_from_landmarks(landmarks, img_size)\n",
    "        \n",
    "        # Преобразование изображения в вектор\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Отрисовка точек на руке\n",
    "        frame = draw_hand_landmarks(frame, landmarks, (frame.shape[1], frame.shape[0]))\n",
    "        \n",
    "        # Предсказание с помощью вашей нейронной сети\n",
    "        predicted_number = model.predict(img_array)\n",
    "\n",
    "        # Отображение результата\n",
    "        cv2.putText(frame, f\"Number: {np.argmax(predicted_number, axis=1)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Отображение кадра\n",
    "    cv2.imshow('Gesture Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Очистка ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
